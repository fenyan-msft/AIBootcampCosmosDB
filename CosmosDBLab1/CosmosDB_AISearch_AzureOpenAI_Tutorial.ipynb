{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this tutorial, we'll demonstrate the RAG pattern using a sample dataset stored in Azure Cosmos DB to ground OpenAI models. We'll do this taking advantage of Azure AI Search's vector similarity search functionality. At the end, we'll create an interactive chat session with the GPT-3.5 completions model to answer questions about Azure services informed by our dataset. \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Create the conda environment\n",
        "\n",
        "Start a terminal from the CosmosDBLab1 folder and run the following commands **sequentially**. Respond `y` when asked\n",
        ":\n",
        "\n",
        "```\n",
        "conda create --name CDBAISearch_env python=3.10\n",
        "\n",
        "conda activate CDBAISearch_env\n",
        "\n",
        "pip install ipykernel\n",
        "\n",
        "python -m ipykernel install --user --name CDBAISearch_env --display-name \"CDBAISearch_env\"\n",
        "\n",
        "pip install -r requirements.txt\n",
        "\n",
        "pip install --index-url=https://pkgs.dev.azure.com/azure-sdk/public/_packaging/azure-sdk-for-python/pypi/simple/ azure-search-documents==11.4.0a20230509004\n",
        "```\n",
        "\n",
        "In this notebook, select the CDBAISearch_env kernel. You may need to close and reopen this notebook to select it"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Import Modules <a class=\"anchor\" id=\"preliminaries\"></a>\n",
        "Next we'll import the required modules."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "from azure.core.exceptions import AzureError\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.cosmos import exceptions, CosmosClient, PartitionKey\n",
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
        "from azure.search.documents.models import Vector\n",
        "from azure.search.documents.indexes.models import (\n",
        "    IndexingSchedule,\n",
        "    SearchIndex,\n",
        "    SearchIndexer,\n",
        "    SearchIndexerDataContainer,\n",
        "    SearchField,\n",
        "    SearchFieldDataType,\n",
        "    SearchableField,\n",
        "    SemanticConfiguration,\n",
        "    SimpleField,\n",
        "    PrioritizedFields,\n",
        "    SemanticField,\n",
        "    SemanticSettings,\n",
        "    VectorSearch,\n",
        "    VectorSearchAlgorithmConfiguration,\n",
        "    SearchIndexerDataSourceConnection\n",
        ")\n",
        "\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988381040
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Create an Azure Cosmos DB for NoSQL resource\n",
        "Create a Cosmos DB account as follows:  \n",
        "\n",
        "**Subscription**: *Select your subscription*  \n",
        "**Resource Group**: *Select/Create a resource group*  \n",
        "**Account name**: *Enter a unique name. The name can contain only lowercase letters, numbers and the \"-\" character*  \n",
        "**Availability Zones**: *Disable*  \n",
        "**Location**: *Select a location*  \n",
        "**Capacity mode**: *Serverless*  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Create an Azure AI Search resource\n",
        "Create an Azure AI Search resource on the `Basic` tier"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Create an Azure OpenAI resource and deploy models\n",
        "Create an Azure OpenAI resource and deploy `text-embedding-ada-002` and `gpt-35-turbo` models, if you don't already have these deployed."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Complete the env template\n",
        "Add the keys and endpoints to the cdbaisearch_env.env file in this folder. Where there are values entered, please do not change them.  \n",
        "Then run the next cell. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import dotenv_values\n",
        "\n",
        "# specify the name of the .env file name \n",
        "env_name = \"cdbaisearch_env.env\" # following example.env template change to your own .env file name\n",
        "config = dotenv_values(env_name)\n",
        "\n",
        "cosmosdb_endpoint = config['cosmos_db_api_endpoint']\n",
        "cosmosdb_key = config['cosmos_db_api_key']\n",
        "cosmosdb_connection_str = config['cosmos_db_connection_string']\n",
        "cosmosdb_database = config['cosmos_db_database']\n",
        "\n",
        "cog_search_endpoint = config['cognitive_search_api_endpoint']\n",
        "cog_search_key = config['cognitive_search_api_key']\n",
        "\n",
        "openai_api_type = config['openai_api_type']\n",
        "openai_api_key = config['openai_api_key']\n",
        "openai_api_endpoint = config['openai_api_endpoint']\n",
        "openai_api_version = config['openai_api_version']\n",
        "embeddings_deployment = config['openai_embeddings_deployment']\n",
        "completions_deployment = config['openai_completions_deployment']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988414073
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Load data and create embeddings\n",
        "Here we'll load a sample dataset containing descriptions of Azure services. Then we'll user Azure OpenAI to create vector embeddings from this data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Load text-sample.json data file\n",
        "data_file = open(file=\"DataSet/text-sample.json\", mode=\"r\")\n",
        "data = json.load(data_file)\n",
        "data_file.close()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988418247
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a peek at one data item\n",
        "print(data[0])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988420755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the AOAI client\n",
        "AOAI_client = AzureOpenAI(api_key=openai_api_key, azure_endpoint=openai_api_endpoint, api_version=openai_api_version,)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1721988424322
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate embeddings\n",
        "def generate_embeddings(text):\n",
        "    '''\n",
        "    Generate embeddings from string of text.\n",
        "    This will be used to vectorize data and user input for interactions with Azure OpenAI.\n",
        "    '''\n",
        "    response = AOAI_client.embeddings.create(\n",
        "        input=text, model=embeddings_deployment)\n",
        "    embeddings = response.model_dump()\n",
        "    time.sleep(0.5) # rest period to avoid rate limiting on AOAI for free tier\n",
        "    return embeddings['data'][0]['embedding']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988427603
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for title and content fields\n",
        "for item in data:\n",
        "    title = item['title']\n",
        "    content = item['content']\n",
        "    title_embeddings = generate_embeddings(title)\n",
        "    content_embeddings = generate_embeddings(content)\n",
        "    item['titleVector'] = title_embeddings\n",
        "    item['contentVector'] = content_embeddings\n",
        "    item['@search.action'] = 'upload'\n",
        "\n",
        "# Save embeddings to sample_text_w_embeddings.json file\n",
        "with open(\"DataSet/text-sample_w_embeddings.json\", \"w\") as f:\n",
        "    json.dump(data, f)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988553220
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Upload data to Azure Cosmos DB"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the client to interact with the Azure Cosmos DB resource\n",
        "client = CosmosClient(cosmosdb_endpoint, cosmosdb_key)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988566619
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a database in Azure Cosmos DB.\n",
        "try:\n",
        "    database = client.create_database_if_not_exists(id=\"VectorSearchTutorial\")\n",
        "    print(f\"Database created: {database.id}\")\n",
        "\n",
        "except exceptions.CosmosResourceExistsError:\n",
        "    print(\"Database already exists.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988569293
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a container in Azure Cosmos DB.\n",
        "try:\n",
        "    partition_key_path = PartitionKey(path=\"/id\")\n",
        "    container = database.create_container_if_not_exists(\n",
        "        id=\"AzureServices\",\n",
        "        partition_key=partition_key_path#,\n",
        "        # offer_throughput=400,\n",
        "    )\n",
        "    print(f\"Container created: {container.id}\")\n",
        "\n",
        "except exceptions.CosmosResourceExistsError:\n",
        "    print(\"Container already exists.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988574187
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data items for every entry in the dataset, insert them into the database and collection specified above.\n",
        "for data_item in data:\n",
        "    try:\n",
        "        container.create_item(body=data_item)\n",
        "    \n",
        "    except exceptions.CosmosResourceExistsError:\n",
        "        print(\"Data item already exists.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988586889
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Create a search index in AI Search \n",
        "Let's create the Search Index over all fields we have in our Azure Cosmos DB collection. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create index\n",
        "\n",
        "cog_search_cred = AzureKeyCredential(cog_search_key)\n",
        "index_name = \"cosmosdb-vector-search-index\"\n",
        "\n",
        "# Create a search index and define the schema (names, types, and parameters)\n",
        "index_client = SearchIndexClient(\n",
        "    endpoint=cog_search_endpoint, credential=cog_search_cred)\n",
        "fields = [\n",
        "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
        "    SearchableField(name=\"title\", type=SearchFieldDataType.String,\n",
        "                    searchable=True, retrievable=True),\n",
        "    SearchableField(name=\"content\", type=SearchFieldDataType.String,\n",
        "                    searchable=True, retrievable=True),\n",
        "    SearchableField(name=\"category\", type=SearchFieldDataType.String,\n",
        "                    filterable=True, searchable=True, retrievable=True),\n",
        "    SearchField(name=\"titleVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
        "                searchable=True, dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
        "    SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
        "                searchable=True, dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
        "]\n",
        "\n",
        "# Configure vector search\n",
        "vector_search = VectorSearch(\n",
        "    algorithm_configurations=[\n",
        "        VectorSearchAlgorithmConfiguration(\n",
        "            name=\"my-vector-config\",\n",
        "            kind=\"hnsw\",\n",
        "            hnsw_parameters={\n",
        "                \"m\": 4,\n",
        "                \"efConstruction\": 400,\n",
        "                \"efSearch\": 1000,\n",
        "                \"metric\": \"cosine\"\n",
        "            }\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Configure semantic search. This will allow us to conduct semantic or hybrid search (with vector search) later on if desired.\n",
        "semantic_config = SemanticConfiguration(\n",
        "    name=\"my-semantic-config\",\n",
        "    prioritized_fields=PrioritizedFields(\n",
        "        title_field=SemanticField(field_name=\"title\"),\n",
        "        prioritized_keywords_fields=[SemanticField(field_name=\"category\")],\n",
        "        prioritized_content_fields=[SemanticField(field_name=\"content\")]\n",
        "    )\n",
        ")\n",
        "\n",
        "# Create the semantic settings with the configuration\n",
        "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
        "\n",
        "# Create the search index with the semantic settings\n",
        "index = SearchIndex(name=index_name, fields=fields,\n",
        "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
        "result = index_client.create_or_update_index(index)\n",
        "print(f' {result.name} created')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988592607
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Create an indexer to pull data from Cosmos DB into Cognitive Search\n",
        "Now we'll create the indexer, which will retrieve data from our Azure Cosmos DB resource. Learn more about Azure Cognitive Search Indexers [here](https://learn.microsoft.com/azure/search/search-howto-create-indexers)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create indexer\n",
        "\n",
        "def _create_datasource():\n",
        "    # Here we create a datasource. \n",
        "    ds_client = SearchIndexerClient(cog_search_endpoint, cog_search_cred)\n",
        "    container = SearchIndexerDataContainer(name=\"AzureServices\")\n",
        "    cosmosdb_connection = cosmosdb_connection_str + cosmosdb_database\n",
        "    data_source_connection = SearchIndexerDataSourceConnection(\n",
        "        name=\"cosmosdb-tutorial-indexer\", type=\"cosmosdb\", connection_string=cosmosdb_connection, container=container\n",
        "    )\n",
        "    data_source = ds_client.create_or_update_data_source_connection(data_source_connection)\n",
        "    return data_source\n",
        "\n",
        "ds_name = _create_datasource().name\n",
        "\n",
        "indexer = SearchIndexer(\n",
        "        name=\"cosmosdb-tutorial-indexer\",\n",
        "        data_source_name=ds_name,\n",
        "        target_index_name=index_name)\n",
        "\n",
        "indexer_client = SearchIndexerClient(cog_search_endpoint, cog_search_cred)\n",
        "indexer_client.create_or_update_indexer(indexer)  # create the indexer\n",
        "\n",
        "result = indexer_client.get_indexer(\"cosmosdb-tutorial-indexer\")\n",
        "print(result)\n",
        "\n",
        "# Run the indexer we just created.\n",
        "indexer_client.run_indexer(result.name)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988600091
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have setup our resources, data, and configured Azure Cognitive Search to index data from Azure Cosmos DB, let's try performing a vector similarity search."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple function to assist with vector search\n",
        "def vector_search(query):\n",
        "    search_client = SearchClient(cog_search_endpoint, index_name, cog_search_cred)  \n",
        "    results = search_client.search(  \n",
        "        search_text=\"\",  \n",
        "        vector=Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\"),  \n",
        "        select=[\"title\", \"content\", \"category\"] \n",
        "    )\n",
        "    return results"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988606047
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run a test query below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"tools for software development\"  \n",
        "results = vector_search(query)\n",
        "for result in results:  \n",
        "    print(f\"Title: {result['title']}\")  \n",
        "    print(f\"Score: {result['@search.score']}\")  \n",
        "    print(f\"Content: {result['content']}\")  \n",
        "    print(f\"Category: {result['category']}\\n\")  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988609622
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Q&A over the data with GPT-3.5\n",
        "\n",
        "Finally, we'll create a helper function to feed prompts to the `Completions` model. Then we'll create interactive loop where you can pose questions to the model and receive information grounded in your data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#This function helps \n",
        "\n",
        "def generate_completion(prompt):\n",
        "    system_prompt = '''\n",
        "    You are an intelligent assistant for Microsoft Azure services.\n",
        "    You are designed to provide helpful answers to user questions about Azure services given the information about to be provided.\n",
        "        - Only answer questions related to the information provided below, provide clear suggestions in a list format.\n",
        "        - Write two lines of whitespace between each answer in the list.\n",
        "        - Only provide answers that have products that are part of Microsoft Azure.\n",
        "        - If you're unsure of an answer, you can say \"\"I don't know\"\" or \"\"I'm not sure\"\" and recommend users search themselves.\"\n",
        "    '''\n",
        "\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_input},\n",
        "    ]\n",
        "\n",
        "    for item in results:\n",
        "        messages.append({\"role\": \"system\", \"content\": prompt['content']})\n",
        "\n",
        "    response = AOAI_client.chat.completions.create(model=completions_deployment, messages=messages)\n",
        "    \n",
        "    return response"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988755714
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a loop of user input and model output. You can now perform Q&A over the sample data! \n",
        "# For example, try \"What database services are there in Azure?\", \"Which relational databases are there in Azure?\"\n",
        "\n",
        "user_input = \"\"\n",
        "print(\"*** Please ask your model questions about Azure services. Type 'end' to end the session.\\n\")\n",
        "user_input = input(\"Prompt: \")\n",
        "while user_input.lower() != \"end\":\n",
        "    results_for_prompt = vector_search(user_input)\n",
        "    completions_results = generate_completion(results_for_prompt)\n",
        "    completions_results = completions_results.model_dump()\n",
        "    print(\"\\n\")\n",
        "    print(completions_results['choices'][0]['message']['content'])\n",
        "    user_input = input(\"Prompt: \")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1721988850707
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "aisearch_env",
      "language": "python",
      "display_name": "AISearch_env"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "aisearch_env"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}